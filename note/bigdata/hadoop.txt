cloudera下

	hadoop启动关闭脚本	/usr/lib/hadoop/sbin
	hbase启动关闭脚本	/usr/lib/hbase/bin
	
	配置文件路径
	/etc/hadoop/conf
	/etc/hive/conf
	/etc/hbase/conf

	mysql安装路径
	/var/lib/mysql
	
hdfs
HDFS基本命令:
hadoop fs -cmd
cmd: 具体的操作，基本上与UNIX的命令行相同
args:参数
示例：hadoop fs -ls
HDFS资源URI格式：scheme://authority/path
scheme：协议名，file或hdfs
authority：namenode主机名
path：路径
示例：hdfs://localhost:9000/user/chunk/test.txt

在core-site.xml里配置了 fs.default.name=hdfs://localhost:9000，则仅使用/user/chunk/test.txt即可。

hadoop fs -put local_path hdfs_path   ###将本地文件上传到hdfs
hadoop fs -get hdfs_path local_path	  ###将hdfs文件下载到本地


hive
关系型分布式数据库，数据文件存储于hdfs上。默认在/user/hive/

元数据存储库使用mysql，默认端口3306
hiveServer默认端口10000

hive sell   ###进入hive

使用方式与mysql类似
hive不支持行级插入，支持【insert into ... select ...】

导数据到本地
hive -e "select * from test" >> res.csv     ####执行sql命令
hive -f sql.q >> res.csv    ####执行sql文件

查看文件，也可以执行其他命令，如get、put
dfs -ls /;



hive数据插入
load data local inpath 'wyp.txt' into table wyp;       ###从本地文件导入
load data inpath '/home/wyp/add.txt' into table wyp;   ###从hdfs文件导入
insert into ... select ...;
create table ... as select ...;

hbase
非关系型分布式数据库，数据文件存储于hdfs上


create 'test', 'cf'
put 'test', 'row2', 'cf:d', 'value2'
get 'test', 'row2', {COLUMN=>'cf:d'}
scan 'test'       








